# LLM-Based Research Agent

This project involves the creation of a research agent that utilizes serverless Large Language Model (LLM) endpoints. The agent is designed to handle a research topic, gather relevant information, and generate a concise summary based on the findings. This README provides an overview of the tools and workflow implemented in the project.

## Getting Started

To begin, you'll need to create an account with a serverless LLM provider. For this project, Together AI was chosen, but you can also explore other providers like Anthropic, OpenAI, Mistral, Fireworks, OctoAI, or Groq. The cost of API usage is expected to be minimal, and it's recommended to use smaller or mid-sized models for cost efficiency.

### Running the Project

You can run the project on Google Colab or locally using a Jupyter notebook. When using Colab, ensure that your API keys are securely handled to avoid any leaks. The project does not involve loading models locally, as it relies on third-party LLM providers.

## Tools Implemented

### Topic Breakdown Tool
This tool takes a broad research topic and breaks it down into smaller, more focused subtopics or subqueries. An LLM is used to generate these subtopics based on the main topic.

### Query Expansion Tool
This tool expands the subqueries generated by the Topic Breakdown Tool. It generates related keywords, synonyms, and phrases to enhance the search results.

### Search Tool
A wrapper around the You API or Brave Search API, this tool is used to gather relevant information based on the expanded queries and subqueries. It includes considerations for API usage limits and caching.

### Critique Tool
This tool critiques the generated summary and offers suggestions for improvement. It can also suggest other relevant topics to explore.

### Summarizer Tool
This optional tool summarizes the gathered content using an LLM, providing a concise overview of the research topic.

## Agent Workflow

The agent workflow integrates all the tools mentioned above to create a streamlined research process:

1. **Receive Topic**: The agent receives a research topic from the user.
2. **Topic Breakdown**: The Topic Breakdown Tool generates subtopics or subqueries.
3. **Query Expansion**: The Query Expansion Tool expands the subqueries with related keywords and phrases.
4. **Search**: The Search Tool uses the expanded queries to gather information from various sources.
5. **Summarization (optional)**: The agent summarizes the gathered information.
6. **Critique**: The Critique Tool reviews and improves the summary.
7. **Present Summary**: The agent presents the final summary to the user.

## Conclusion

This project provides a comprehensive approach to building an LLM-based research agent. By utilizing serverless LLM endpoints and integrating various tools, the agent is capable of efficiently handling research tasks and generating high-quality summaries. Feel free to experiment with different models and providers to optimize performance and cost.

## Author : nagargoje.a@northeastern.edu (Amar Nagargoje)
## Notebook : https://colab.research.google.com/drive/1GIy_9w7GmBsgBDP3rnwetAYPIJraaqWs?usp=sharing
